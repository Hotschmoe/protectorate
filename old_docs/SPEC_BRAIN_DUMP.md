- docker networks: agents, dev-hosted, prod-hosted (should we also connect across devices with a mesh SDN like tail scale or wireguard+babeld? Do we have a network container that everything proxies through and each device gets a network container so we mesh across devices?)
- agents use subagents as personas (planner, worker, judge, code simplifier) we don't give personas to containers
- run go exe install to get device to join resource pool or launch a container in docker that begins spawning siblings? (Do we install a single go executable that then sets up docker and all system containers and manager is actually outside docker? Or (better imo) we have install script that setups docker, networks and initiates manager container. Manager container is itself the project orchestrator to spin up sub systems sibling containers like gitea, webui, and agent containers, this would require manager to have docker socket access, can a container create host directories for other containers to mount or would the setup script get that squared away before manager starts? Manager then provisions agent containers with their own mounts, etc) (like it would be *really* easy from a user side to provision a new device by running a single container that grows into our monster!)
- use babeld and poll available resources or similar so agents know which 'fat build' container is closer and available across all the physical devices on the network 
- agent sidecar should have all CLIs installed so we maintain only one sidecar image
- i dont want random agent-xyz generic lame names when we spin up a new agent container, we should have a list of names to pull from or generate them in a more fun way (we can keep a list of names in the repo)
- stack and agent docs as separate repo?
- nail down dogfooding for rapid dev
- stack is a separate, abstracted persistent memory platform that saves to the git repo, any agent can use (each repo should have a AGENTS.md CLAUDE.md .Claude .agents (skills and mcp?) and .stack and we should keep those up to date on updates.
- stack should have a version number so if it updates from md to sqlite or to beads repo migrates correctly (should we just use beads and agent mail to start? Plan is to have one long running, often cleared, agent per repo, not a hundred agents per repo)
- while one agent per repo, we need to have repo "pairings" ie -> repo 1 has a dependency on repo 2 so the two agents should have some form of communication so repo 1 agent can request "hey we need a new syscall in kernel to make compiler work" then repo 2 agent can implement new syscall and respond to repo 1 agent when that is completed so repo 1 agent can update and run successful compile (see laminae(new kernel and os) and laminae-zig(bootstrapping compiler to new kernel))
- local gitea or gitlab with build actions for release so we don't hammer GitHub (once a week or on big releases we push mirrors to GitHub for data persistence)
- local git also allows much easier authentication for agents, GitHub no password hurts us
- maybe local git PRs and issue/bug trackers replaces our repo pairing and agent mail communication? (Won't muddy the mirrored GitHub repo right?)
- traefik or other reverse proxy Auto discover containers in dev or prod hosted network 
- figure out shared mounts (no shared? Manager see each working directory? How does this work across device? Do we care?)
- figure out UI, probably separate container so anyone can make their own UI
- figure out messaging app integration (telegram, slack, sms, self hosted version like matrix or something?)
- in docker we can use other containers like grafana for metric or whatever
- if we keep all repos in a mount location, not per container (which we shouldn't per container so we can resleeve to a new container with same repo not redownload) and if manager can see all then we could also run a container for visual studio code (or forks?) so users have a IDE to *all* working repos!
- we should have a import by GitHub or maybe easier local script? So users can mirror down to local git their existing repos and in UI they should see all their repos local and remote so they can start new agent by repo?
- resleeve by having agent container swap CLI or actually spin up new container and mount drive, kill old container?
- have warm agent container pool and a warm build container for agents to hand off build tasks (can it transfer built files or save to a shared location so requesting agent can be notified when done and run tests on built product?)
- do agents or manager actually deploy to production or do we push repos with tagged releases and only tagged releases get prod built and hosted (this can be hard coded automation no agent container right?)
- across multi device how do we share "shared" mounts? Is this easy and I don't know or is it hard enough that we should push multi device support for later
- need serious version tracking so we don't get stale containers through rapid development and a watchdog container to update agents and managers quickly on new releases (watch tower?) - need to be sure manager, agents and related subsystems stay in sync on same version so we don't get miscommunication or stale communication from version mismatch
- will gitea/gitlab host locally built docker images or how should we handle that?
- IMPORTANT -> WE NEED TO BE COMPLETELY PORTABLE. IF AN AGENT OR CONTAINER DESTROYS THE HOST IT SHOULD NOT AFFECT US. REPOSITORIES AND STACKS ARE SAVED TO GITEA(WITH BACKUP PLAN) AND MIRRORED TO GITHUB(PROTECTED? NO DELETES?). WE SHOULD LOSE NOTHING IF ANY CONTAINER OR HOST GOES DOWN. IT IS A SIMPLE SLEEVE. THE CONTAINERS AND EVEN THE HOST ARE SIMPLE SLEEVES! ANY REQUIRED PERSISTENT DATA NEEDS TO BE IDENTIFIED AND RESOLVED OFF DEVICE. AT ANY MOMENT WE SHOULD BE ABLE TO NUKE THE HOST AND STARTUP THE MAIN REPO DOCKERCOMPOSE OR GO EXECTUABLE WHATEVER IT IS WITH OUR API KEYS (.ENV? SECRETS? WHATEVER) AND START RIGHT WHERE WE LEFT OFF GIVE OR TAKE A FEW HOURS)